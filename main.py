# MIT License
# 
# Copyright (c) 2024 TechFish4
# 
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
# 
# The above copyright notice and this permission notice shall be included in all
# copies or substantial portions of the Software.
# 
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
# SOFTWARE.
import os
import discord
from discord.ext import commands
from transformers import AutoProcessor, FocalNetForImageClassification, pipeline, AutoModelForSeq2SeqLM
from transformers import AutoTokenizer
from PIL import Image
import torch
from torchvision import transforms
import io
from dotenv import load_dotenv
import asyncio

load_dotenv()

DISCORD_TOKEN = os.getenv('DISCORD_TOKEN')

# ã‚¤ãƒ³ãƒ†ãƒ³ãƒˆã®è¨­å®š
intents = discord.Intents.default()
intents.message_content = True
intents.guilds = True
intents.messages = True
intents.reactions = True  # ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã«é–¢ã™ã‚‹ã‚¤ãƒ³ãƒ†ãƒ³ãƒˆã‚’è¿½åŠ 

bot = commands.Bot(command_prefix='!', intents=intents)

# ç”»åƒãƒ¢ãƒ‡ãƒ«ã®è¨­å®š
model_path = "MichalMlodawski/nsfw-image-detection-large"
feature_extractor = AutoProcessor.from_pretrained(model_path)
model = FocalNetForImageClassification.from_pretrained(model_path)
model.eval()
transform = transforms.Compose([
    transforms.Resize((512, 512)),
    transforms.ToTensor(),
    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
])
classifier = pipeline("image-classification", model="Falconsai/nsfw_image_detection")

# ãƒ†ã‚­ã‚¹ãƒˆè§£æãƒ¢ãƒ‡ãƒ«ã®è¨­å®š
text_model_name = "eliasalbouzidi/distilbert-nsfw-text-classifier"
text_classifier = pipeline("text-classification", model=text_model_name)

# ç¿»è¨³ãƒ¢ãƒ‡ãƒ«ã®è¨­å®šï¼ˆNLLBãƒ¢ãƒ‡ãƒ«: æ—¥æœ¬èªâ†’è‹±èªï¼‰
translation_model_name = "facebook/m2m100_1.2B"
translation_tokenizer = AutoTokenizer.from_pretrained(translation_model_name)
translation_model = AutoModelForSeq2SeqLM.from_pretrained(translation_model_name)

class StatusButton(discord.ui.View):
    def __init__(self):
        super().__init__()
        self.add_item(discord.ui.Button(label="Discord BOT Status", url="https://status.sakana-cloud.f5.si/status/techfish"))

@bot.event
async def on_ready():
    print(f'Logged in as {bot.user}')
    await bot.tree.sync()  # Sync commands with Discord

@bot.tree.command(name="help", description="NSFW Detector Bot ã®ä½¿ã„æ–¹ã‚’è¡¨ç¤ºã—ã¾ã™ã€‚")
async def nsfw_help(interaction: discord.Interaction):
    embed = discord.Embed(
        title="NSFW Detector Bot ä½¿ã„æ–¹",
        description=("ã“ã®ãƒœãƒƒãƒˆã¯ã€ç”»åƒã¨ãƒ†ã‚­ã‚¹ãƒˆãŒNSFWï¼ˆNot Safe For Workï¼‰ã‹ã©ã†ã‹ã‚’åˆ¤æ–­ã—ã¾ã™ã€‚\n\n"
                     "ç”»åƒã‚„ãƒ†ã‚­ã‚¹ãƒˆã‚’å«ã‚€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã«å¯¾ã—ã¦ã€@NSFW Detector ã‚’ãƒªãƒ—ãƒ©ã‚¤ã¨ã—ã¦è¿”ä¿¡ã—ã¦ãã ã•ã„ã€‚\n\n"
                     "ã“ã®ãƒœãƒƒãƒˆã¯ä»¥ä¸‹ã®AIãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨ã—ã¦è§£æã—ã¾ã™:\n"
                     "1. **MichalMlodawski/nsfw-image-detection-large**: SAFE, QUESTIONABLE, UNSAFE\n"
                     "2. **Falconsai/nsfw_image_detection**: SAFE, NSFW\n"
                     "3. **eliasalbouzidi/distilbert-nsfw-text-classifier**: SAFE, NSFW (ãƒ†ã‚­ã‚¹ãƒˆè§£æ)\n\n"
                     "çµæœã«åŸºã¥ãã€æœ€çµ‚åˆ¤å®šã‚’è¡Œã„ã¾ã™ã€‚"),
        color=discord.Color.blue()
    )
    view = StatusButton()
    await interaction.response.send_message(embed=embed, view=view)

@bot.event
async def on_message(message):
    if message.author == bot.user:
        return

    if bot.user in message.mentions:
        if message.reference and message.reference.message_id:
            ref_message = await message.channel.fetch_message(message.reference.message_id)
            analyzing_msg = await message.channel.send("è§£æä¸­...")

            # ç”»åƒã®è§£æ
            if ref_message.attachments:
                for attachment in ref_message.attachments:
                    if attachment.filename.lower().endswith(('jpg', 'jpeg', 'png')):
                        await analyze_image(attachment, message, analyzing_msg, None)

            # ãƒ†ã‚­ã‚¹ãƒˆã®è§£æ
            if ref_message.content:
                await analyze_text(ref_message.content, message, analyzing_msg)

    # ç”»åƒãŒå˜ç‹¬ã§é€ã‚‰ã‚ŒãŸã¨ãã®å‡¦ç†
    if message.attachments:
        for i, attachment in enumerate(message.attachments):
            if attachment.filename.lower().endswith(('jpg', 'jpeg', 'png')):
                # ç”»åƒã®å‡¦ç†ã‚’éåŒæœŸã«å®Ÿè¡Œ
                await analyze_image(attachment, message, None, i + 1)

async def is_nsfw_image(attachment):
    # ç”»åƒã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
    image_bytes = await attachment.read()
    image = Image.open(io.BytesIO(image_bytes)).convert("RGB")

    # ãƒ¢ãƒ‡ãƒ«æ¨è«–ã‚’éåŒæœŸã«å®Ÿè¡Œ
    label_1, confidence_1 = await asyncio.to_thread(run_model_1, image)
    label_2, confidence_2 = await asyncio.to_thread(run_model_2, image)

    # é«˜ã„ä¿¡é ¼åº¦ã®ãƒ©ãƒ™ãƒ«ã‚’æœ€çµ‚åˆ¤å®šã«ä½¿ç”¨
    final_label = 'SAFE'
    if confidence_1 > confidence_2:
        final_label = label_1
    else:
        final_label = label_2

    return final_label == 'UNSAFE'

def run_model_1(image):
    # ãƒ¢ãƒ‡ãƒ«1ã«ã‚ˆã‚‹è§£æ
    image_tensor = transform(image).unsqueeze(0)
    inputs = feature_extractor(images=image, return_tensors="pt")
    with torch.no_grad():
        outputs = model(**inputs)
        probabilities = torch.nn.functional.softmax(outputs.logits, dim=-1)
        confidence_1, predicted_1 = torch.max(probabilities, 1)
    label_1 = model.config.id2label[predicted_1.item()]
    confidence_1 = confidence_1.item()

    return label_1, confidence_1

def run_model_2(image):
    # ãƒ¢ãƒ‡ãƒ«2ã«ã‚ˆã‚‹è§£æ
    result = classifier(image)[0]
    label_2 = result['label']
    confidence_2 = result['score']

    # ãƒ©ãƒ™ãƒ«ã®å¤‰æ›
    label_2 = 'SAFE' if label_2 == 'normal' else 'UNSAFE'

    return label_2, confidence_2

async def analyze_image(attachment, message, analyzing_msg, index):
    # ç”»åƒã‚’ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ã—ã¦è§£æ
    image_bytes = await attachment.read()
    image = Image.open(io.BytesIO(image_bytes)).convert("RGB")

    # ãƒ¢ãƒ‡ãƒ«æ¨è«–ã‚’éåŒæœŸã«å®Ÿè¡Œ
    label_1, confidence_1 = await asyncio.to_thread(run_model_1, image)
    label_2, confidence_2 = await asyncio.to_thread(run_model_2, image)

    # é«˜ã„ä¿¡é ¼åº¦ã®ãƒ©ãƒ™ãƒ«ã‚’æœ€çµ‚åˆ¤å®šã«ä½¿ç”¨
    final_label = 'SAFE'
    if confidence_1 > confidence_2:
        final_label = label_1
    else:
        final_label = label_2

    # ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ã•ã‚ŒãŸæ™‚ã ã‘åŸ‹ã‚è¾¼ã¿ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ä½œæˆ
    if not analyzing_msg:
        return

    embed = discord.Embed(
        title=f"ğŸ–¼ï¸ NSFW ã‚³ãƒ³ãƒ†ãƒ³ãƒ„åˆ¤å®šçµæœ ({index}) ğŸ–¼ï¸",
        description=(f"ğŸ“„ **ãƒ•ã‚¡ã‚¤ãƒ«å**: {attachment.filename}\n"
                     f"ğŸ” **ãƒ¢ãƒ‡ãƒ«1ã®åˆ¤å®šãƒ©ãƒ™ãƒ«**: {label_1} (ä¿¡é ¼åº¦: {confidence_1 * 100:.2f}%)\n"
                     f"ğŸ” **ãƒ¢ãƒ‡ãƒ«2ã®åˆ¤å®šãƒ©ãƒ™ãƒ«**: {label_2} (ä¿¡é ¼åº¦: {confidence_2 * 100:.2f}%)\n\n"
                     f"**æœ€çµ‚åˆ¤å®šçµæœ**: {final_label}\n\n"
                     "ã“ã®ç”»åƒã®å†…å®¹ã‚’ï¼’ã¤ã®AIã§ç¢ºèªã—ã¾ã—ãŸã€‚ä¸Šè¨˜ã®çµæœã‚’å‚è€ƒã«ã—ã¦ãã ã•ã„ã€‚"),
        color=discord.Color.green() if final_label == 'SAFE' else discord.Color.red()
    )

    # è§£æä¸­ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä¸Šæ›¸ã
    if analyzing_msg:
        await analyzing_msg.edit(content=None, embed=embed)
    
    # ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®è¿½åŠ ï¼ˆãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ã•ã‚Œã¦ã„ãªã„ã¨ãã®ã¿ï¼‰
    if analyzing_msg:
        await message.add_reaction(f'{index}\u20e3')  # ä¾‹: 1ï¸âƒ£ ãªã©ã®ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’è¿½åŠ 
        final_reaction = 'âœ…' if final_label == 'SAFE' else 'ğŸ”'
        await message.add_reaction(final_reaction)

async def analyze_text(text, message, analyzing_msg):
    # æ—¥æœ¬èªã‚’è‹±èªã«ç¿»è¨³
    translated = await translate_to_english(text)

    # NSFWãƒ†ã‚­ã‚¹ãƒˆè§£æã‚’éåŒæœŸã«å®Ÿè¡Œ
    result = await asyncio.to_thread(text_classifier, translated)
    label = result[0]['label']
    confidence = result[0]['score']

    # ãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ã•ã‚ŒãŸæ™‚ã ã‘åŸ‹ã‚è¾¼ã¿ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®ä½œæˆ
    embed = discord.Embed(
        title="ğŸ“ ãƒ†ã‚­ã‚¹ãƒˆè§£æçµæœ ğŸ“",
        description=(f"**ç¿»è¨³æ–‡**: {translated}\n\n"
                     f"**åˆ¤å®šãƒ©ãƒ™ãƒ«**: {label}\n"
                     f"**ä¿¡é ¼åº¦**: {confidence * 100:.2f}%\n\n"
                     "ãƒ†ã‚­ã‚¹ãƒˆã®å†…å®¹ã‚’è§£æã—ã€æœ€çµ‚åˆ¤å®šã‚’è¡Œã„ã¾ã—ãŸã€‚"),
        color=discord.Color.green() if label == 'SAFE' else discord.Color.red()
    )

    # è§£æä¸­ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’ä¸Šæ›¸ã
    if analyzing_msg:
        await analyzing_msg.edit(content=None, embed=embed)

    # ãƒªã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã®è¿½åŠ ï¼ˆãƒ¡ãƒ³ã‚·ãƒ§ãƒ³ã•ã‚ŒãŸã¨ãã¯ä¸è¦ï¼‰
    if analyzing_msg:
        final_reaction = 'âœ…' if label == 'SAFE' else 'ğŸ”'
        await message.add_reaction(final_reaction)

async def translate_to_english(text):
    inputs = translation_tokenizer(text, return_tensors="pt")
    outputs = translation_model.generate(**inputs)
    translated = translation_tokenizer.decode(outputs[0], skip_special_tokens=True)
    return translated

bot.run(DISCORD_TOKEN)
